{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MASK-Maintaining Data Privacy in Association Rule Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](\n",
    "link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_ds_path = \".\\..\\Datasets\\store_data.csv\"\n",
    "\n",
    "with open(test_ds_path, \"r\") as f:\n",
    "\n",
    "    lines = f.readlines()\n",
    "    inventory = list()\n",
    "    tuples = list()\n",
    "\n",
    "    for line in lines:\n",
    "        transaction = line.strip().split(\",\")\n",
    "        #print(transaction)\n",
    "        tuples.append(transaction)\n",
    "        for element in transaction:\n",
    "            if element.strip().replace(' ','_').replace('&','and') not in inventory:\n",
    "                inventory.append(element.strip().replace(' ','_').replace('&','and'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(inventory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(inventory)\n",
    "inventory.pop()\n",
    "inventory.sort()\n",
    "print(inventory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(inventory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "from pandas import DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = pd.DataFrame(\n",
    "    [[1 if item in row else 0 for item in inventory] for row in tuples],\n",
    "    columns=inventory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(test_dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tuple in test_dataset.itertuples():\n",
    "    print(tuple)\n",
    "    print(int( getattr(tuple, 'almonds')))\n",
    "    print(type(tuple))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import float64\n",
    "class Rule:\n",
    "    def __init__(self,itemset: list | dict,support: float = 0, confidence: float = 0):\n",
    "        self.itemset = itemset\n",
    "        self.support = support\n",
    "        self.confidence = confidence\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Rule('{self.itemset}', '{self.support}')\"\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Rule('{self.itemset}', '{self.support}')\"\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, Rule):\n",
    "            return set(self.itemset) == set(other.itemset)\n",
    "        return False\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return iter([self.itemset, self.support, self.confidence])\n",
    "    \n",
    "\n",
    "class AprioriRule(Rule):\n",
    "    def __init__(self,itemset: list | dict,support: float64 = 0):\n",
    "        super().__init__(itemset,support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pandas import DataFrame\n",
    "\n",
    "\n",
    "def support(T: DataFrame ,X_U_Y: list | dict):\n",
    "    '''\n",
    "    Parameters:\n",
    "    T (dataframe)\n",
    "    X_U_Y (list | dict) : name of the attributes considered (X U Y)\n",
    "    Return:\n",
    "    float: support of the attributes in the dataset\n",
    "    '''\n",
    "    for attribute in X_U_Y:\n",
    "        if attribute not in T.columns:\n",
    "             return ValueError\n",
    "    count = 0\n",
    "    for tuple in T.itertuples(False):\n",
    "        contained = True\n",
    "        for attribute in X_U_Y:\n",
    "            try: \n",
    "                if getattr(tuple,attribute) == 0:\n",
    "                    contained = False\n",
    "                    break\n",
    "            except AttributeError:\n",
    "                contained = False,\n",
    "                break\n",
    "\n",
    "        if contained:\n",
    "            count += 1\n",
    "    return count/len(T)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "support(test_dataset,['herb_and_pepper'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def confidence(T: DataFrame, X: list | dict, Y: list | dict):\n",
    "    '''\n",
    "    Parameters:\n",
    "    T (dataframe)\n",
    "    X ( list | dict): X part of X ==> Y rule\n",
    "    X (list | dict): Y part of X ==> Y rule\n",
    "    '''\n",
    "    if len(X)+len(Y) > len(T.columns):\n",
    "        return ValueError\n",
    "    for item in X:\n",
    "        if Y.__contains__(item):\n",
    "            return ValueError # XY = empty set\n",
    "    \n",
    "    countX=0\n",
    "    countY=0\n",
    "    for tuple in T.itertuples():\n",
    "        containedX = True\n",
    "        for attribute in X:\n",
    "            if getattr(tuple,attribute) == 0:\n",
    "                containedX = False\n",
    "                break\n",
    "        if containedX:\n",
    "            countX += 1\n",
    "            containedY=True\n",
    "            for attribute in Y:\n",
    "                if attribute == '':\n",
    "                    containedY = False\n",
    "                    break\n",
    "                if getattr(tuple,attribute) == 0:\n",
    "                    containedY = False\n",
    "                    break\n",
    "            if containedY:\n",
    "                countY += 1\n",
    "    return countY/countX    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence(test_dataset,['spaghetti','champagne'],['cookies'])\n",
    "#spaghetti,champagne,cookies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Apriori(items, dataset, min_sup, levels: int = None):\n",
    "    if levels is None:\n",
    "        levels = len(items)\n",
    "    '''\n",
    "    rules[0] = empty set\n",
    "    rules[1] = rules of length 1\n",
    "    rules[2] = rules of length 2\n",
    "\n",
    "\n",
    "    rules[len(items)] = items\n",
    "    ...\n",
    "    '''\n",
    "    rules = [\n",
    "        [],\n",
    "        [ AprioriRule([item]) for item in items ]\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "    # iterate over all the possible rules length from 1 to len(items)\n",
    "    for i in range(1, levels+1):\n",
    "        print(f\"Apriori Level: {i}\")\n",
    "        # remove all the rules in rules[i]\n",
    "        # that don't have a support of at least min_sup\n",
    "\n",
    "        #print(f\"RULES[{i}] BEFORE\", rules[i])\n",
    "        for j in range(len(rules[i])-1,-1,-1):\n",
    "            sup = support(dataset,rules[i][j].itemset)\n",
    "            if sup >= min_sup:\n",
    "                rules[i][j].support = sup\n",
    "            else:\n",
    "                rules[i].remove(rules[i][j])\n",
    "    \n",
    "        '''\n",
    "        print(f\"RULES[{i}] SUPPORT\", [\n",
    "            support(dataset, rule)\n",
    "            for rule in rules[i]\n",
    "        ]\n",
    "        )'''\n",
    "\n",
    "\n",
    "        #print(f\"RULES[{i}] AFTER\", rules[i])\n",
    "\n",
    "        if len(rules[i]) == 0:\n",
    "            break\n",
    "\n",
    "\n",
    "        # generate all the possibile \n",
    "        # rules with i+1 elements\n",
    "        rules.append([]) # create the element rules[i+1]\n",
    "\n",
    "        #print(\"RULE[i]\", rules[i])\n",
    "        #print(\"RULE[i+1]\", rules[i+1])\n",
    "        for rule in rules[i]:\n",
    "            for item in items:\n",
    "\n",
    "                # skip if item is already inside the rule\n",
    "                if item in rule.itemset:\n",
    "                    continue\n",
    "\n",
    "                rules[i+1].append ( AprioriRule(rule.itemset + [item]))\n",
    "                # create a new rule composed of rule + [item]\n",
    "\n",
    "\n",
    "    return rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_vector = [[item,support(test_dataset,[item])] for item in inventory]\n",
    "print(support_vector)\n",
    "mean_support = np.mean([sublist[1] for sublist in support_vector])\n",
    "print(mean_support)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def MASK_Distortion(dataset: DataFrame, p: float):\n",
    "    '''\n",
    "    MASK\n",
    "    \n",
    "    choose a probability p\n",
    "\n",
    "    2 event\n",
    "    P(x = true) -> 1-p % -> we add or remove an element in the transaction\n",
    "    P(x = false) -> p% -> the transaction remains the same\n",
    "    '''\n",
    "    distorted_dataset = dataset.copy(deep=True)\n",
    "    for i in range(0,len(distorted_dataset)):\n",
    "        for column in distorted_dataset.columns:\n",
    "            event = random.random()\n",
    "            if event > p:\n",
    "                distorted_dataset.loc[i, column] = int(not dataset.loc[i, column])\n",
    "\n",
    "    return distorted_dataset\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.9\n",
    "distorted_test_dataset = MASK_Distortion(test_dataset,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hammingDistanceBitwise(a:int,b:int):\n",
    "    return (a^b).bit_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hammingDistanceBitwise(int(1),int(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "M = np.diag([math.pow(2,3) for i in range(0,3)])\n",
    "print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def computeM(size: int, p: float):\n",
    "    max_exp = int(math.log2(size))\n",
    "    M = np.diag([math.pow(p,max_exp) for i in range(size)])\n",
    "    for i in range(0,size):\n",
    "        for j in range(i+1,size):\n",
    "            difference = hammingDistanceBitwise(i,j)\n",
    "            M[i][j] = math.pow(1-p,difference)*math.pow(p,max_exp-difference)\n",
    "\n",
    "    for i in range(1,size):\n",
    "        for j in range(i,-1,-1):\n",
    "            M[i][j] = M[j][i]\n",
    "\n",
    "    return M\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_test = computeM(int(math.pow(2,2)),0.1)\n",
    "print(M_test)\n",
    "print(sum(M_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectormatrixProdMod(linC_D,matrix):\n",
    "    size = matrix.shape[0]\n",
    "    row = matrix[size-1]\n",
    "    sum:float = 0.0\n",
    "    for j in range(len(linC_D)):\n",
    "        index = int(math.pow(2,j))-1\n",
    "        #print(str(row[index])+\" * \"+str(linC_D[j]))\n",
    "        sum += row[index]*linC_D[j]\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import inv\n",
    "\n",
    "M_test = inv(computeM(2**2,p))\n",
    "print(M_test)\n",
    "print(sum(M_test[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MASKRule(Rule):\n",
    "    def __init__(self,itemset: list | dict,support: float = 0):\n",
    "        super().__init__(itemset,support)\n",
    "        self.counters = np.zeros(len(itemset)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MASK_Support(linC_D,db_cardinality,M_inv = None):\n",
    "    if M_inv is None:\n",
    "        M_inv = inv(\n",
    "            computeM(\n",
    "                size=int(math.pow(2,len(linC_D)-1)),\n",
    "                p=p\n",
    "            )\n",
    "        )\n",
    "\n",
    "    C_T_11 = vectormatrixProdMod(linC_D,M_inv)\n",
    "\n",
    "    return C_T_11/db_cardinality\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def MASK_Rule_Mining(dataset: DataFrame, p: float, min_sup: float,levels: int = None):\n",
    "    if levels is None:\n",
    "        levels = len(dataset.columns)\n",
    "    rules = [\n",
    "        [],\n",
    "    ]\n",
    "    frequent_itemsets = [[]]\n",
    "    infrequent_itemsets = [[]]\n",
    "\n",
    "    for i in range(1,levels+1):\n",
    "        print(f\"Mask Rule Mining level: {i}\")\n",
    "\n",
    "        combinations = list(itertools.combinations(dataset.columns,i))\n",
    "        rule_i = [\n",
    "            MASKRule(sorted(list(c)))for c in combinations]\n",
    "        rules.append(rule_i)\n",
    "\n",
    "        frequent_itemsets.append([])\n",
    "        infrequent_itemsets.append([])\n",
    "\n",
    "\n",
    "        for tuple in dataset.itertuples():\n",
    "\n",
    "            item_list = []\n",
    "            complement_list=[]\n",
    "\n",
    "            for item in dataset.columns:\n",
    "                if getattr(tuple,item) == 1 and item not in infrequent_itemsets[i-1]:\n",
    "                    item_list.append(item)\n",
    "            for item in frequent_itemsets[i-1]:\n",
    "                if item not in item_list:\n",
    "                    complement_list.append(item)\n",
    "\n",
    "           \n",
    "            for rule in rules[i]:\n",
    "                bit_counter = 0\n",
    "                for item in rule.itemset:\n",
    "                    if item in item_list:\n",
    "                        bit_counter += 1\n",
    "                \n",
    "                rule.counters[bit_counter]+=1\n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "        for j in range(len(rules[i])-1,-1,-1):\n",
    "\n",
    "            size = int(math.pow(2,i))\n",
    "            M_inv = inv(\n",
    "                computeM(size,p)\n",
    "            )\n",
    "\n",
    "            sup = MASK_Support(rules[i][j].counters,len(dataset),M_inv)\n",
    "\n",
    "            if sup >= min_sup:\n",
    "                rules[i][j].support = sup\n",
    "                for item in rules[i][j].itemset:\n",
    "                    if item not in frequent_itemsets[i]:\n",
    "                        frequent_itemsets[i].append(item)\n",
    "\n",
    "            else:\n",
    "                rules[i].remove(rules[i][j])\n",
    "                for item in rule.itemset:\n",
    "                    if item not in infrequent_itemsets[i]:\n",
    "                        infrequent_itemsets[i].append(item)\n",
    "            \n",
    "        if len(rules[i]) == 0:\n",
    "            break\n",
    "    \n",
    "    return rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_inventory = inventory[0:50]\n",
    "print(reduced_inventory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_test_ds = test_dataset.iloc[:, 0:50]\n",
    "print(reduced_test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_vector_reduced = [[item,support(reduced_test_ds,[item])] for item in reduced_inventory]\n",
    "print(support_vector_reduced)\n",
    "mean_reduced_support = np.mean([sublist[1] for sublist in support_vector_reduced])\n",
    "print(mean_reduced_support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.9\n",
    "reduced_distorted_test_ds = MASK_Distortion(reduced_test_ds,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sup = 0.01\n",
    "rules = Apriori(reduced_inventory,reduced_test_ds,min_sup)\n",
    "print(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK_rules = MASK_Rule_Mining(reduced_distorted_test_ds,p,min_sup)\n",
    "#print(MASK_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MASK_rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating performance of the algorithm\n",
    "### Metrics\n",
    "* Support Error:\n",
    "    $\\rho = \\frac{1}{|f|}\\sum_{f}^{}\\frac{|recSup_f - actSup_f|}{actSup_f}*100 $\n",
    "* Identity error:\n",
    "    $\\sigma^+$ = percentage of false positive\n",
    "    $\\sigma^-$ = percentage of false negative\n",
    "\n",
    "    $\\sigma^+ = \\frac{|R-F|}{|F|}*100$      $\\sigma^- = \\frac{|F-R|}{|F|}*100$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def support_error(AprioriRuleslevel,MASKRuleslevel):\n",
    "    \n",
    "    sum = 0\n",
    "    cnt = 0\n",
    "\n",
    "    for apriorirule in AprioriRuleslevel:\n",
    "        if apriorirule is not None and apriorirule in MASKRuleslevel:\n",
    "            cnt += 1\n",
    "            index = MASKRuleslevel.index(apriorirule)\n",
    "            \n",
    "            rec_sup = MASKRuleslevel[index].support\n",
    "            act_sup = apriorirule.support\n",
    "            \n",
    "            sum += abs(rec_sup-act_sup)/act_sup\n",
    "    if cnt != 0:\n",
    "        return (sum/cnt)*100\n",
    "    else:\n",
    "        return 0\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_error(AprioriRulesLevel,MASKRulesLevel):\n",
    "\n",
    "    false_positive_cnt = 0\n",
    "    false_negative_cnt = 0\n",
    "\n",
    "    for rule in AprioriRulesLevel:\n",
    "        if rule not in MASKRulesLevel:\n",
    "            false_positive_cnt += 1\n",
    "    \n",
    "    for rule in MASKRulesLevel:\n",
    "        if rule not in AprioriRulesLevel:\n",
    "            false_negative_cnt += 1\n",
    "    \n",
    "    F = len(AprioriRulesLevel)\n",
    "\n",
    "    if F != 0:\n",
    "        false_positive = false_positive_cnt/F\n",
    "        false_negative = false_negative_cnt/F\n",
    "        return false_positive, false_negative\n",
    "    else: return 0,0\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,len(rules)):\n",
    "    print(support_error(rules[i],MASK_rules[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,len(rules)):\n",
    "    print(identity_error(rules[i],MASK_rules[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating MASK's privacy\n",
    "### Metrics:\n",
    "* Reconstruction Probability:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
